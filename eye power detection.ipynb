!pip install tensorflow
import os
import numpy as np
import librosa
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import load_model
import speech_recognition as sr

# Mapping for misinterpretations
misinterpretation_map = {
    'yeah': 'A', 'yee': 'A', 'ay': 'A', 'eh': 'A',
    'bee': 'B', 'buh': 'B', 'be': 'B',
    'see': 'C', 'sea': 'C', 'cee': 'C', 'si': 'C',
    'dee': 'D', 'di': 'D', 'd': 'D', 'de': 'D',
    'ee': 'E', 'e': 'E', 'eh': 'E', 'i': 'E',
    'ef': 'F', 'eff': 'F', 'f': 'F',
    'gee': 'G', 'ji': 'G', 'g': 'G',
    'aitch': 'H', 'h': 'H', 'ha': 'H',
    'eye': 'I', 'i': 'I',
    'jay': 'J', 'j': 'J',
    'kay': 'K', 'k': 'K', 'kei': 'K',
    'el': 'L', 'l': 'L', 'ell': 'L',
    'emm': 'M', 'em': 'M', 'm': 'M', 'yam': 'M', 'yem': 'M',
    'en': 'N', 'n': 'N', 'yen': 'N', 'yan': 'N',
    'oh': 'O', 'o': 'O',
    'pee': 'P', 'p': 'P',
    'queue': 'Q', 'q': 'Q', 'cue': 'Q',
    'are': 'R', 'r': 'R', 'aur': 'R',
    'ess': 'S', 's': 'S', 'es': 'S', 'yes': 'S',
    'tee': 'T', 't': 'T', 'ti': 'T',
    'you': 'U', 'u': 'U',
    'vee': 'V', 'v': 'V',
    'double-u': 'W', 'w': 'W', 'dubya': 'W',
    'ex': 'X', 'x': 'X',
    'why': 'Y', 'y': 'Y',
    'zee': 'Z', 'z': 'Z', 'zed': 'Z'
}
def prepare_dataset(audio_dir):
    labels = []
    features = []
    for file in os.listdir(audio_dir):
        if file.endswith('.wav'):
            label = file[0]
            audio_path = os.path.join(audio_dir, file)
            audio, sr = librosa.load(audio_path, sr=None)
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            mfccs_mean = np.mean(mfccs.T, axis=0)
            features.append(mfccs_mean)
            labels.append(label)

    X = np.array(features)
    y = np.array(labels)
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    
    return X, y_encoded, le

def train_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = Sequential()
    model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(len(np.unique(y)), activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))
    model.save('alphabet_recognition_model.h5')
    print("Model trained and saved as 'alphabet_recognition_model.h5'.")
def calculate_logMAR(total_errors, total_rows):
    """Calculate LogMAR using the formula: LogMAR = Total Rows - (Total Errors / 2)"""
    return total_rows - (total_errors / 2)

def calculate_eye_power(logMAR):
    """Calculate eye power based on LogMAR."""
    if logMAR == 0:
        return 20  # Perfect vision is represented as 20/20
    return round(1 - logMAR, 2)  # Calculate eye power

def compare_detected_with_actual(detected_letters, actual_letters):
    errors = sum(1 for det, actual in zip(detected_letters, actual_letters) if det != actual)
    return errors

snellen_chart = [
    ("E", 6/60),        # Row 1: Large letter for very poor vision
    ("FP", 6/36),       # Row 2: Common letters at this level
    ("TOZ", 6/24),      # Row 3: Vision getting better
    ("LPED", 6/18),     # Row 4: Moderate vision
    ("PECFD", 6/12),    # Row 5: Near normal vision
    ("EDFCZP", 6/9),    # Row 6: Very good vision
    ("FELOPZD", 6/6),   # Row 7: Perfect vision (20/20)
    ("DEFPOTEC", 6/5),  # Row 8: Better than 20/20 vision
    ("LEFODPCT", 6/4),  # Row 9: Exceptional vision
    ("RDPLTCEO", 6/3),  # Row 10: High-level vision
    ("PEZOLCFTD", 6/2)  # Row 11: Extreme sharpness (rare)
]
def recognize_snellen_chart(snellen_chart, model, label_encoder):
    r = sr.Recognizer()
    total_errors = 0
    total_rows = len(snellen_chart)

    with sr.Microphone() as source:
        print("Adjusting for ambient noise...")
        r.adjust_for_ambient_noise(source)

        for row_num, (actual_letters, _) in enumerate(snellen_chart, start=1):
            while True:  # Loop until the row is successfully recorded
                print(f"Please say the letters for Snellen chart row {row_num}...")
                audio = r.listen(source)
                print("Recording complete.")

                try:
                    recognized_text = r.recognize_google(audio).lower()
                    print(f"You said: {recognized_text}")

                    # Map misinterpretations
                    words = recognized_text.split()
                    mapped_letters = []

                    for word in words:
                        mapped_letter = misinterpretation_map.get(word)
                        if mapped_letter:
                            mapped_letters.append(mapped_letter)
                        else:
                            mapped_letters.append(word)  # Add the original word if no mapping exists

                    detected_letters = ''.join(mapped_letters)
                    print(f"Detected letters for row {row_num}: {detected_letters}")
                    print(f"Actual letters for row {row_num}: {actual_letters}")

                    # Calculate errors (ignoring case by converting both to lowercase)
                    row_errors = sum(1 for detected, actual in zip(detected_letters.lower(), actual_letters.lower()) if detected != actual)
                    print(f"Errors in row {row_num}: {row_errors}")

                    total_errors += row_errors

                    if row_errors >= len(actual_letters):  # Too many errors in the row
                        print(f"Too many errors in row {row_num}. Moving to the next row.")
                    break  # Exit loop and move to the next row even with errors

                except sr.UnknownValueError:
                    print("Could not understand audio, please try again for the same row.")
                except sr.RequestError as e:
                    print(f"Could not request results from Google Speech Recognition service; {e}")
                    break  # Exit the loop if there's a request error

    return total_errors
if __name__ == '__main__':
    audio_path = "C:\\Users\\muthu\\OneDrive\\Desktop\\alphabet_audio"  # Change this to your audio path
    X, y, label_encoder = prepare_dataset(audio_dir=audio_path)

    # Train the model (only once, you don't need to call this every time)
    train_model(X, y)

    # Load the trained model for real-time recognition
    model = load_model('alphabet_recognition_model.h5')

    # Perform real-time speech recognition and calculate eye power
    total_errors = recognize_snellen_chart(snellen_chart, model, label_encoder)
    logMAR = calculate_logMAR(total_errors, len(snellen_chart))
    eye_power = calculate_eye_power(logMAR)

    print(f"Total errors: {total_errors}")
    print(f"Visual acuity (eye power): {eye_power} diopters")
